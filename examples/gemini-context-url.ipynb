{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using URLs as Context with Gemini\n",
    "\n",
    "This notebook demonstrates how to provide URLs as context to the Gemini API. The `url_context` tool allows Gemini to extract content from provided URLs as additional context for prompts. This is useful if you want to provide additional uptodate or external context to the model that is not available as part of the internal knowledge of the model.\n",
    "\n",
    "When `url_context` is enabled the model will use all provided URLs (up to 20) to inform its response. This can be combined with `google_search` to provide a broader context before using the URLs. See below for 2 examples.\n",
    "\n",
    "Url context is currently in preview without any billing. Quotas are 1500 queries/day/project (API), 100 queries/day/user (AI Studio).\n",
    "\n",
    "**Supported Models:**\n",
    "*   `gemini-2.5-pro-preview-05-06`\n",
    "*   `gemini-2.5-flash-preview-05-20`\n",
    "*   `gemini-2.0-flash`\n",
    "*   `gemini-2.0-flash-live-001`\n",
    "\n",
    "For more details, see the [official documentation](https://ai.google.dev/gemini-api/docs/url-context).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%uv pip install google-genai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**url context, multiple urls**\n",
    "\n",
    "Will use the `llms.txt` for gemini by example to generate a snippet on how create an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The Gemini API allows you to generate text from various inputs, including text, images, video, and audio. To get started, you'll need a Gemini API key, which you can obtain for free from Google AI Studio.\n",
      "\n",
      "Here's an example of how to use Gemini in Python for text generation:\n",
      "\n",
      "**1. Install the Google GenAI SDK:**\n",
      "\n",
      "First, install the necessary library using pip:\n",
      "`pip install -q -U google-genai`\n",
      "\n",
      "**2. Make your first request:**\n",
      "\n",
      "Once the SDK is installed, you can make a request to the Gemini API. Remember to replace `\"YOUR_API_KEY\"` with your actual API key.\n",
      "\n",
      "```python\n",
      "from google import genai\n",
      "\n",
      "# Configure your API key\n",
      "genai.configure(api_key=\"YOUR_API_KEY\")\n",
      "\n",
      "# Choose a model\n",
      "model = genai.GenerativeModel('gemini-pro') # You can also use 'gemini-2.0-flash' or other available models. [1]\n",
      "\n",
      "# Generate content\n",
      "prompt = \"Explain how AI works in a few words.\"\n",
      "response = model.generate_content(prompt)\n",
      "\n",
      "# Print the generated text\n",
      "print(response.text)\n",
      "```\n",
      "This example demonstrates a basic text generation request. You can also configure system instructions to guide the model's behavior, adjust generation parameters like `temperature` and `max_output_tokens`, and even send multimodal inputs that combine text with images.\n",
      "\n",
      "For more advanced use cases, the SDK provides functionalities for multi-turn conversations (chat) and streaming responses.\n",
      "Context Retrieval: None\n",
      "Search Pages: Text generation | Gemini API | Google AI for Developers, Gemini API quickstart | Google AI for Developers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google import genai\n",
    "\n",
    "# create client\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\",\"xxx\"))\n",
    "\n",
    "# Generate a list of cookie recipes\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-preview-05-20\",\n",
    "    contents='Create a example on how to use Gemini? Using the docs https://ai.google.dev/gemini-api/docs/text-generation https://ai.google.dev/gemini-api/docs/quickstart',\n",
    "    config={\"tools\": [{\"url_context\": {}}]},\n",
    ")\n",
    "\n",
    "# print the response\n",
    "print(f\"Response: {response.text}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Context used: https://ai.google.dev/gemini-api/docs/text-generation, https://ai.google.dev/gemini-api/docs/quickstart\n"
     ]
    }
   ],
   "source": [
    "# urls used for grounding\n",
    "print(f\"Context used: {', '.join([url.retrieved_url for url in response.candidates[0].url_context_metadata.url_metadata])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[GroundingSupport(confidence_scores=[1.0], grounding_chunk_indices=[0], segment=Segment(end_index=104, part_index=None, start_index=None, text='The Gemini API allows you to generate text from various inputs, including text, images, video, and audio')),\n",
       "  GroundingSupport(confidence_scores=[1.0], grounding_chunk_indices=[1], segment=Segment(end_index=203, part_index=None, start_index=106, text=\"To get started, you'll need a Gemini API key, which you can obtain for free from Google AI Studio\")),\n",
       "  GroundingSupport(confidence_scores=[1.0], grounding_chunk_indices=[1], segment=Segment(end_index=395, part_index=None, start_index=315, text='First, install the necessary library using pip:\\n`pip install -q -U google-genai`')),\n",
       "  GroundingSupport(confidence_scores=[1.0], grounding_chunk_indices=[1], segment=Segment(end_index=1015, part_index=None, start_index=948, text='text)\\n```\\nThis example demonstrates a basic text generation request')),\n",
       "  GroundingSupport(confidence_scores=[1.0], grounding_chunk_indices=[0], segment=Segment(end_index=1225, part_index=None, start_index=1017, text=\"You can also configure system instructions to guide the model's behavior, adjust generation parameters like `temperature` and `max_output_tokens`, and even send multimodal inputs that combine text with images\")),\n",
       "  GroundingSupport(confidence_scores=[1.0], grounding_chunk_indices=[0], segment=Segment(end_index=1349, part_index=None, start_index=1228, text='For more advanced use cases, the SDK provides functionalities for multi-turn conversations (chat) and streaming responses'))]]"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# citations\n",
    "[response.candidates[0].grounding_metadata.grounding_supports]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Combine with Context URL with Google Search\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: The latest versions of the libraries are:\n",
      "*   `fastapi`: `0.115.12`\n",
      "*   `uvicorn`: `0.34.2`\n",
      "\n",
      "Here is the `pip install` command:\n",
      "```bash\n",
      "pip install fastapi==0.115.12 uvicorn==0.34.2\n",
      "```\n",
      "Context used: https://gist.github.com/ultrafunkamsterdam/b1655b3f04893447c3802453e05ecb5e\n",
      "Website used: FastAPI support for React ( with working react-router ) Â· GitHub, pypi.org\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google import genai\n",
    "\n",
    "# create client\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\",\"xxx\"))\n",
    "\n",
    "# Generate a list of cookie recipes\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-preview-05-20\",\n",
    "    contents='find the latest versions of the libraries used here and create a pip install command. https://gist.github.com/ultrafunkamsterdam/b1655b3f04893447c3802453e05ecb5e',\n",
    "    config={\"tools\": [\n",
    "        {\"url_context\": {}},\n",
    "        {\"google_search\": {}},\n",
    "    ]},\n",
    ")\n",
    "\n",
    "# print the response\n",
    "print(f\"Response: {response.text}\")\n",
    "# urls used for grounding\n",
    "print(f\"Context used: {', '.join([url.retrieved_url for url in response.candidates[0].url_context_metadata.url_metadata])}\")\n",
    "# searched websited \n",
    "print(f\"Website used: {', '.join([site.web.title for site in response.candidates[0].grounding_metadata.grounding_chunks])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
