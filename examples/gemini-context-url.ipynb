{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using URLs as Context with Gemini\n",
    "\n",
    "This notebook demonstrates how to provide URLs as context to the Gemini API. The `url_context` tool allows Gemini to extract content from provided URLs as additional context for prompts. This is useful if you want to provide additional uptodate or external context to the model that is not available as part of the internal knowledge of the model.\n",
    "\n",
    "When `url_context` is enabled the model will use all provided URLs (up to 20) to inform its response. This can be combined with `google_search` to provide a broader context before using the URLs. See below for 2 examples.\n",
    "\n",
    "Url context is currently in preview without any billing. Quotas are 1500 queries/day/project (API), 100 queries/day/user (AI Studio).\n",
    "\n",
    "**Supported Models:**\n",
    "*   `gemini-2.5-pro-preview-05-06`\n",
    "*   `gemini-2.5-flash-preview-05-20`\n",
    "*   `gemini-2.0-flash`\n",
    "*   `gemini-2.0-flash-live-001`\n",
    "\n",
    "For more details, see the [official documentation](https://ai.google.dev/gemini-api/docs/url-context).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%uv pip install google-genai --upgrade"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**url context, multiple urls**\n",
    "\n",
    "Will use the `llms.txt` for gemini by example to generate a snippet on how create an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Response: To use the Gemini API, you'll need a Gemini API key, which you can obtain for free from Google AI Studio.\n",
      "\n",
      "Here's an example of how to use Gemini in Python:\n",
      "\n",
      "**1. Installation**\n",
      "\n",
      "First, install the `google-genai` package using pip:\n",
      "\n",
      "```bash\n",
      "pip install -q -U google-genai\n",
      "```\n",
      "\n",
      "**2. Set up your API key**\n",
      "\n",
      "You should set your API key as an environment variable (e.g., `GEMINI_API_KEY`) for security and convenience.\n",
      "\n",
      "```python\n",
      "import os\n",
      "from google import genai\n",
      "\n",
      "# Set your API key as an environment variable (e.g., GEMINI_API_KEY)\n",
      "# os.environ[\"GEMINI_API_KEY\"] = \"YOUR_API_KEY\"\n",
      "\n",
      "# Initialize the Gemini client\n",
      "client = genai.Client(api_key=os.environ.get(\"GEMINI_API_KEY\"))\n",
      "```\n",
      "\n",
      "**3. Basic Text Generation**\n",
      "\n",
      "You can generate text by calling the `generate_content` method on a model, providing a text prompt.\n",
      "\n",
      "```python\n",
      "# Choose a model, for example, \"gemini-2.0-flash\"\n",
      "model = \"gemini-2.0-flash\"\n",
      "\n",
      "# Generate content from a single text input\n",
      "response = client.models.generate_content(\n",
      "    model=model,\n",
      "    contents=\"Explain how large language models work in a few sentences.\"\n",
      ")\n",
      "\n",
      "print(\"Basic Text Generation:\")\n",
      "print(response.text)\n",
      "print(\"-\" * 30)\n",
      "```\n",
      "\n",
      "**4. Using System Instructions and Generation Parameters**\n",
      "\n",
      "You can guide the model's behavior with `system_instruction` and control output characteristics like `temperature` and `max_output_tokens` using `GenerateContentConfig`.\n",
      "\n",
      "```python\n",
      "from google.genai import types\n",
      "\n",
      "# Generate content with system instructions and custom parameters\n",
      "response_with_config = client.models.generate_content(\n",
      "    model=model,\n",
      "    config=types.GenerateContentConfig(\n",
      "        system_instruction=\"You are a helpful assistant that responds in a concise and direct manner.\",\n",
      "        max_output_tokens=100,  # Limit the output length\n",
      "        temperature=0.5         # Control the randomness of the output\n",
      "    ),\n",
      "    contents=\"What is the capital of France?\"\n",
      ")\n",
      "\n",
      "print(\"Text Generation with System Instructions and Parameters:\")\n",
      "print(response_with_config.text)\n",
      "print(\"-\" * 30)\n",
      "```\n",
      "\n",
      "**5. Multi-turn Conversations (Chat)**\n",
      "\n",
      "The SDKs provide functionality to manage multi-turn conversations, allowing you to maintain context across multiple user inputs and model responses.\n",
      "\n",
      "```python\n",
      "# Create a chat session\n",
      "chat = client.chats.create(model=model)\n",
      "\n",
      "print(\"Multi-turn Conversation (Chat):\")\n",
      "\n",
      "# Send the first message\n",
      "chat_response1 = chat.send_message(\"I have 3 cats and 2 dogs in my house.\")\n",
      "print(f\"User: I have 3 cats and 2 dogs in my house.\")\n",
      "print(f\"Gemini: {chat_response1.text}\")\n",
      "\n",
      "# Send a follow-up message, the model remembers the previous context\n",
      "chat_response2 = chat.send_message(\"How many legs are there in total?\")\n",
      "print(f\"User: How many legs are there in total?\")\n",
      "print(f\"Gemini: {chat_response2.text}\")\n",
      "\n",
      "print(\"\\nChat History:\")\n",
      "for message in chat.get_history():\n",
      "    print(f'Role - {message.role}: {message.parts[0].text}')\n",
      "print(\"-\" * 30)\n",
      "```\n",
      "Context Retrieval: None\n",
      "Search Pages: Gemini API quickstart | Google AI for Developers, Text generation | Gemini API | Google AI for Developers\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "from google import genai\n",
    "\n",
    "# create client\n",
    "client = genai.Client(api_key=os.getenv(\"GEMINI_API_KEY\",\"xxx\"))\n",
    "\n",
    "\n",
    "# Generate a list of cookie recipes\n",
    "response = client.models.generate_content(\n",
    "    model=\"gemini-2.5-flash-preview-05-20\",\n",
    "    contents='Create a example on how to use Gemini? Using the docs https://ai.google.dev/gemini-api/docs/text-generation https://ai.google.dev/gemini-api/docs/quickstart',\n",
    "    config={\"tools\": [{\"url_context\": {}}]},\n",
    ")\n",
    "\n",
    "# print the response\n",
    "print(f\"Response: {response.text}\")\n",
    "# print the search details\n",
    "print(f\"Context Retrieval: {response.candidates[0].grounding_metadata.web_search_queries}\")\n",
    "# urls used for grounding\n",
    "print(f\"Search Pages: {', '.join([site.web.title for site in response.candidates[0].grounding_metadata.grounding_chunks])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Search Pages: https://ai.google.dev/gemini-api/docs/text-generation, https://ai.google.dev/gemini-api/docs/quickstart\n"
     ]
    }
   ],
   "source": [
    "# urls used for grounding\n",
    "print(f\"Context used: {', '.join([url.retrieved_url for url in response.candidates[0].url_context_metadata.url_metadata])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[GroundingSupport(confidence_scores=[1.0], grounding_chunk_indices=[0], segment=Segment(end_index=105, part_index=None, start_index=None, text=\"To use the Gemini API, you'll need a Gemini API key, which you can obtain for free from Google AI Studio.\")),\n",
       "  GroundingSupport(confidence_scores=[1.0], grounding_chunk_indices=[0], segment=Segment(end_index=231, part_index=None, start_index=179, text='First, install the `google-genai` package using pip:')),\n",
       "  GroundingSupport(confidence_scores=[1.0, 1.0], grounding_chunk_indices=[1, 0], segment=Segment(end_index=809, part_index=None, start_index=710, text='You can generate text by calling the `generate_content` method on a model, providing a text prompt.')),\n",
       "  GroundingSupport(confidence_scores=[1.0], grounding_chunk_indices=[1], segment=Segment(end_index=1383, part_index=None, start_index=1214, text=\"You can guide the model's behavior with `system_instruction` and control output characteristics like `temperature` and `max_output_tokens` using `GenerateContentConfig`.\")),\n",
       "  GroundingSupport(confidence_scores=[1.0], grounding_chunk_indices=[1], segment=Segment(end_index=2202, part_index=None, start_index=2054, text='The SDKs provide functionality to manage multi-turn conversations, allowing you to maintain context across multiple user inputs and model responses.'))]]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# citations\n",
    "[response.candidates[0].grounding_metadata.grounding_supports]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
